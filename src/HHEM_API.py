"""
HHEMäº‹å®ä¸€è‡´æ€§è¯„ä¼°APIå°è£…
ä½¿ç”¨Vectaraçš„HHEMæ¨¡å‹æ¥è¯„ä¼°ç”Ÿæˆæ–‡æœ¬ä¸æºæ–‡æœ¬ä¹‹é—´çš„äº‹å®ä¸€è‡´æ€§
"""

import requests
import json
from typing import List, Dict, Optional, Union
import os
from dataclasses import dataclass


@dataclass
class HHEMResponse:
    """HHEM APIå“åº”æ•°æ®ç±»"""
    score: float
    success: bool
    error_message: Optional[str] = None
    raw_response: Optional[Dict] = None


class HHEMFactualConsistencyAPI:
    """
    HHEMäº‹å®ä¸€è‡´æ€§è¯„ä¼°APIå°è£…ç±»
    
    ç”¨äºè¯„ä¼°ç”Ÿæˆæ–‡æœ¬ä¸å‚è€ƒæ–‡æœ¬ä¹‹é—´çš„äº‹å®ä¸€è‡´æ€§
    åˆ†æ•°èŒƒå›´: 0-1ï¼Œè¶Šæ¥è¿‘1è¡¨ç¤ºäº‹å®è¶Šä¸€è‡´
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        
        Args:
            api_key: Vectara APIå¯†é’¥ï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡VECTARA_API_KEYè·å–
        """
        self.base_url = "https://api.vectara.io/v2/evaluate_factual_consistency"
        self.api_key = api_key or os.getenv('VECTARA_API_KEY')
        
        if not self.api_key:
            raise ValueError("APIå¯†é’¥æœªæä¾›ï¼è¯·é€šè¿‡å‚æ•°æˆ–ç¯å¢ƒå˜é‡VECTARA_API_KEYæä¾›")
        
        self.headers = {
            'Content-Type': 'application/json',
            'Accept': 'application/json',
            'x-api-key': self.api_key
        }
    
    def evaluate_consistency(
        self, 
        generated_text: str, 
        source_texts: List[str],
        model_name: str = "hhem_v2.3"
    ) -> HHEMResponse:
        """
        è¯„ä¼°ç”Ÿæˆæ–‡æœ¬ä¸æºæ–‡æœ¬çš„äº‹å®ä¸€è‡´æ€§
        
        Args:
            generated_text: éœ€è¦è¯„ä¼°çš„ç”Ÿæˆæ–‡æœ¬
            source_texts: å‚è€ƒæºæ–‡æœ¬åˆ—è¡¨
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸ºhhem_v2.3
            
        Returns:
            HHEMResponse: åŒ…å«è¯„ä¼°åˆ†æ•°å’Œç›¸å…³ä¿¡æ¯çš„å“åº”å¯¹è±¡
        """
        if not generated_text.strip():
            return HHEMResponse(
                score=0.0,
                success=False,
                error_message="ç”Ÿæˆæ–‡æœ¬ä¸èƒ½ä¸ºç©º"
            )
        
        if not source_texts or not any(text.strip() for text in source_texts):
            return HHEMResponse(
                score=0.0,
                success=False,
                error_message="æºæ–‡æœ¬ä¸èƒ½ä¸ºç©º"
            )
        
        # å‡†å¤‡è¯·æ±‚è´Ÿè½½
        payload = {
            "model_parameters": {
                "model_name": model_name
            },
            "generated_text": generated_text.strip(),
            "source_texts": [text.strip() for text in source_texts if text.strip()]
        }
        
        try:
            # å‘é€è¯·æ±‚
            response = requests.post(
                self.base_url,
                headers=self.headers,
                data=json.dumps(payload),
                timeout=30
            )
            
            # æ£€æŸ¥HTTPçŠ¶æ€ç 
            if response.status_code == 200:
                result = response.json()
                return HHEMResponse(
                    score=result.get('score', 0.0),
                    success=True,
                    raw_response=result
                )
            else:
                return HHEMResponse(
                    score=0.0,
                    success=False,
                    error_message=f"HTTP {response.status_code}: {response.text}",
                    raw_response={"status_code": response.status_code, "response": response.text}
                )
                
        except requests.exceptions.Timeout:
            return HHEMResponse(
                score=0.0,
                success=False,
                error_message="è¯·æ±‚è¶…æ—¶"
            )
        except requests.exceptions.RequestException as e:
            return HHEMResponse(
                score=0.0,
                success=False,
                error_message=f"è¯·æ±‚å¼‚å¸¸: {str(e)}"
            )
        except json.JSONDecodeError as e:
            return HHEMResponse(
                score=0.0,
                success=False,
                error_message=f"å“åº”JSONè§£æé”™è¯¯: {str(e)}"
            )
        except Exception as e:
            return HHEMResponse(
                score=0.0,
                success=False,
                error_message=f"æœªçŸ¥é”™è¯¯: {str(e)}"
            )
    
    def batch_evaluate(
        self, 
        evaluations: List[Dict[str, Union[str, List[str]]]],
        model_name: str = "hhem_v2.3"
    ) -> List[HHEMResponse]:
        """
        æ‰¹é‡è¯„ä¼°å¤šä¸ªæ–‡æœ¬å¯¹çš„äº‹å®ä¸€è‡´æ€§
        
        Args:
            evaluations: è¯„ä¼°ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«generated_textå’Œsource_texts
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°
            
        Returns:
            List[HHEMResponse]: è¯„ä¼°ç»“æœåˆ—è¡¨
        """
        results = []
        for i, eval_data in enumerate(evaluations):
            try:
                generated_text = eval_data.get('generated_text', '')
                source_texts = eval_data.get('source_texts', [])
                
                result = self.evaluate_consistency(
                    generated_text=generated_text,
                    source_texts=source_texts,
                    model_name=model_name
                )
                results.append(result)
                
            except Exception as e:
                results.append(HHEMResponse(
                    score=0.0,
                    success=False,
                    error_message=f"æ‰¹é‡è¯„ä¼°ç¬¬{i+1}é¡¹é”™è¯¯: {str(e)}"
                ))
        
        return results
    
    def interpret_score(self, score: float) -> str:
        """
        è§£é‡Šè¯„ä¼°åˆ†æ•°çš„å«ä¹‰
        
        Args:
            score: äº‹å®ä¸€è‡´æ€§åˆ†æ•° (0-1)
            
        Returns:
            str: åˆ†æ•°è§£é‡Š
        """
        if score >= 0.8:
            return "é«˜åº¦ä¸€è‡´ - ç”Ÿæˆæ–‡æœ¬ä¸æºæ–‡æœ¬åœ¨äº‹å®ä¸Šé«˜åº¦ç¬¦åˆ"
        elif score >= 0.6:
            return "è¾ƒä¸ºä¸€è‡´ - ç”Ÿæˆæ–‡æœ¬ä¸æºæ–‡æœ¬åŸºæœ¬ç¬¦åˆï¼Œå­˜åœ¨è½»å¾®å·®å¼‚"
        elif score >= 0.4:
            return "éƒ¨åˆ†ä¸€è‡´ - ç”Ÿæˆæ–‡æœ¬ä¸æºæ–‡æœ¬å­˜åœ¨æ˜æ˜¾å·®å¼‚"
        elif score >= 0.2:
            return "ä¸å¤ªä¸€è‡´ - ç”Ÿæˆæ–‡æœ¬ä¸æºæ–‡æœ¬å­˜åœ¨ä¸¥é‡å·®å¼‚"
        else:
            return "ä¸¥é‡ä¸ä¸€è‡´ - ç”Ÿæˆæ–‡æœ¬ä¸æºæ–‡æœ¬åœ¨äº‹å®ä¸Šä¸¥é‡å†²çª"


def demo_usage():
    """æ¼”ç¤ºAPIä½¿ç”¨æ–¹æ³•"""
    # åˆå§‹åŒ–APIå®¢æˆ·ç«¯ï¼ˆæ³¨æ„ï¼šå®é™…ä½¿ç”¨æ—¶åº”ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰
    api = HHEMFactualConsistencyAPI(api_key="zut_aE6JAgOK4H3CaDxnaz4rEfq8fI9FrYOJr_Es2g")
    
    print("=== HHEMäº‹å®ä¸€è‡´æ€§è¯„ä¼°APIæ¼”ç¤º ===\n")
    
    # å•æ¬¡è¯„ä¼°ç¤ºä¾‹
    print("1. å•æ¬¡è¯„ä¼°ç¤ºä¾‹ï¼š")
    result = api.evaluate_consistency(
        generated_text="å·´é»é“å¡”ä½äºä¼¦æ•¦ï¼Œæ˜¯è‹±å›½è‘—åæ™¯ç‚¹ã€‚",
        source_texts=[
            "åŸƒè²å°”é“å¡”ï¼ˆEiffel Towerï¼‰åè½äºæ³•å›½å·´é»ï¼Œæ˜¯æ³•å›½æœ€è‘—åçš„åœ°æ ‡ä¹‹ä¸€ã€‚",
            "ä¼¦æ•¦æ˜¯è‹±å›½çš„é¦–éƒ½ï¼Œè€Œå·´é»æ˜¯æ³•å›½çš„é¦–éƒ½ã€‚"
        ]
    )
    
    if result.success:
        print(f"âœ… è¯„ä¼°æˆåŠŸ")
        print(f"ğŸ“Š ä¸€è‡´æ€§åˆ†æ•°: {result.score:.4f}")
        print(f"ğŸ“ åˆ†æ•°è§£é‡Š: {api.interpret_score(result.score)}")
    else:
        print(f"âŒ è¯„ä¼°å¤±è´¥: {result.error_message}")
    
    print("\n" + "="*50 + "\n")
    
    # æ‰¹é‡è¯„ä¼°ç¤ºä¾‹
    print("2. æ‰¹é‡è¯„ä¼°ç¤ºä¾‹ï¼š")
    batch_data = [
        {
            "generated_text": "è‹¹æœæ˜¯ä¸€ç§è“è‰²çš„æ°´æœ",
            "source_texts": ["è‹¹æœé€šå¸¸æ˜¯çº¢è‰²ã€ç»¿è‰²æˆ–é»„è‰²çš„æ°´æœ"]
        },
        {
            "generated_text": "åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½",
            "source_texts": ["ä¸­åäººæ°‘å…±å’Œå›½çš„é¦–éƒ½æ˜¯åŒ—äº¬å¸‚"]
        }
    ]
    
    batch_results = api.batch_evaluate(batch_data)
    
    for i, result in enumerate(batch_results, 1):
        print(f"è¯„ä¼°ä»»åŠ¡ {i}:")
        if result.success:
            print(f"  âœ… åˆ†æ•°: {result.score:.4f} - {api.interpret_score(result.score)}")
        else:
            print(f"  âŒ é”™è¯¯: {result.error_message}")


if __name__ == "__main__":
    demo_usage()
