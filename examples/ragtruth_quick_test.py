"""
RAGtruth æ•°æ®é›†å¿«é€Ÿæµ‹è¯•ç¤ºä¾‹
ä½¿ç”¨å°‘é‡æ ·æœ¬æµ‹è¯•è¯„ä¼°ç³»ç»Ÿåœ¨ RAGtruth æ•°æ®é›†ä¸Šçš„è¡¨ç°
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.ragtruth_loader import RAGtruthLoader, TaskType, SplitType
from src.integrated_hallucination_evaluator import IntegratedHallucinationEvaluator, EvaluationMethod


def quick_test_on_ragtruth(max_samples=5, use_qwen=False):
    """åœ¨ RAGtruth æ•°æ®é›†ä¸Šè¿›è¡Œå¿«é€Ÿæµ‹è¯•"""
    method_name = "Qwen" if use_qwen else "HHEM"
    print(f"ğŸš€ RAGtruth æ•°æ®é›†å¿«é€Ÿæµ‹è¯• - ä½¿ç”¨ {method_name}")
    print("=" * 50)
    
    # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
    loader = RAGtruthLoader()
    
    # æ ¹æ®é€‰æ‹©åˆå§‹åŒ–è¯„ä¼°å™¨
    if use_qwen:
        # ä½¿ç”¨ Qwen è¯„ä¼°
        evaluator = IntegratedHallucinationEvaluator(
            dashscope_api_key=os.getenv('DASHSCOPE_API_KEY')
        )
        evaluation_method = EvaluationMethod.QWEN_ONLY
    else:
        # ä½¿ç”¨ HHEM è¯„ä¼°
        evaluator = IntegratedHallucinationEvaluator(
            vectara_api_key="zut_aE6JAgOK4H3CaDxnaz4rEfq8fI9FrYOJr_Es2g"
        )
        evaluation_method = EvaluationMethod.HHEM_ONLY
    
    # è·å–æµ‹è¯•æ ·æœ¬
    print(f"ğŸ“Š è·å–æµ‹è¯•æ ·æœ¬ï¼ˆæœ€å¤š {max_samples} ä¸ªï¼‰...")
    samples = loader.get_samples(
        split=SplitType.TEST,
        max_samples=max_samples,
        random_seed=42
    )
    
    print(f"âœ… è·å–åˆ° {len(samples)} ä¸ªæµ‹è¯•æ ·æœ¬")
    print("\nğŸ” å¼€å§‹è¯„ä¼°:")
    print("-" * 50)
    
    results = []
    
    for i, sample in enumerate(samples, 1):
        print(f"\nğŸ“ æ ·æœ¬ {i}:")
        print(f"   ä»»åŠ¡ç±»å‹: {sample.source.task_type}")
        print(f"   æ¨¡å‹: {sample.response.model}")
        print(f"   å®é™…åŒ…å«å¹»è§‰: {'æ˜¯' if sample.has_hallucination else 'å¦'}")
        
        if sample.has_hallucination:
            print(f"   å¹»è§‰æ•°é‡: {sample.response.hallucination_count}")
            print(f"   å¹»è§‰ç±»å‹: {[label.label_type for label in sample.response.labels]}")
        
        # æ˜¾ç¤ºéƒ¨åˆ†æºä¿¡æ¯å’Œç”Ÿæˆæ–‡æœ¬
        source_info = sample.source.source_info
        if isinstance(source_info, dict):
            source_info_str = str(source_info)
        else:
            source_info_str = str(source_info)
        
        print(f"   æºä¿¡æ¯é•¿åº¦: {len(source_info_str)} å­—ç¬¦")
        print(f"   ç”Ÿæˆæ–‡æœ¬é•¿åº¦: {len(sample.generated_text)} å­—ç¬¦")
        print(f"   ç”Ÿæˆæ–‡æœ¬é¢„è§ˆ: {sample.generated_text[:100]}...")
        
        # æ£€æŸ¥æºä¿¡æ¯æ˜¯å¦æœ‰æ•ˆ
        if len(source_info_str.strip()) < 10:
            print(f"   âš ï¸ æºä¿¡æ¯è¿‡çŸ­ï¼Œè·³è¿‡è¯„ä¼°: '{source_info_str[:50]}'")
            continue
        
        try:
            # æ‰§è¡Œè¯„ä¼°
            result = evaluator.evaluate(
                generated_text=sample.generated_text,
                source_texts=sample.source_texts,
                method=evaluation_method
            )
            
            if result.success:
                if use_qwen and result.qwen_success:
                    score = result.qwen_hallucination_score
                    print(f"   ğŸ¯ Qwenå¹»è§‰åˆ†æ•°: {score:.4f}")
                    print(f"   ğŸ¤– Qwenç½®ä¿¡åº¦: {result.qwen_confidence:.4f}")
                    print(f"   ğŸ“Š Qwenè§£é‡Š: {result.qwen_interpretation}")
                    
                    # Qwenå¹»è§‰åˆ†æ•°è¶Šé«˜è¡¨ç¤ºè¶Šå¯èƒ½æœ‰å¹»è§‰
                    predicted_hallucination = score > 0.2
                    
                elif not use_qwen and result.hhem_success:
                    score = result.hhem_score
                    print(f"   ğŸ¯ HHEMè¯„ä¼°åˆ†æ•°: {score:.4f}")
                    print(f"   ğŸ“Š HHEMè§£é‡Š: {result.hhem_interpretation}")
                    
                    # HHEMåˆ†æ•°è¶Šä½è¡¨ç¤ºè¶Šå¯èƒ½æœ‰å¹»è§‰
                    predicted_hallucination = score < 0.5
                    
                else:
                    print(f"   âŒ {method_name}è¯„ä¼°å¤±è´¥: {result.error_messages}")
                    continue
                
                actual_hallucination = sample.has_hallucination
                
                if predicted_hallucination == actual_hallucination:
                    print(f"   âœ… é¢„æµ‹æ­£ç¡®: {'æœ‰å¹»è§‰' if predicted_hallucination else 'æ— å¹»è§‰'}")
                else:
                    print(f"   âŒ é¢„æµ‹é”™è¯¯: é¢„æµ‹{'æœ‰å¹»è§‰' if predicted_hallucination else 'æ— å¹»è§‰'}ï¼Œå®é™…{'æœ‰å¹»è§‰' if actual_hallucination else 'æ— å¹»è§‰'}")
                
                results.append({
                    'sample_id': i,
                    'actual': actual_hallucination,
                    'predicted': predicted_hallucination,
                    'score': score,
                    'correct': predicted_hallucination == actual_hallucination
                })
            else:
                print(f"   âŒ {method_name}è¯„ä¼°å¤±è´¥: {result.error_messages}")
                
        except Exception as e:
            print(f"   âš ï¸ è¯„ä¼°å¼‚å¸¸: {e}")
    
    # æ€»ç»“ç»“æœ
    print(f"\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“:")
    
    if results:
        correct_predictions = sum(1 for r in results if r['correct'])
        total_predictions = len(results)
        accuracy = correct_predictions / total_predictions
        
        print(f"   æˆåŠŸè¯„ä¼°æ ·æœ¬: {total_predictions}/{len(samples)}")
        print(f"   é¢„æµ‹å‡†ç¡®ç‡: {correct_predictions}/{total_predictions} = {accuracy:.2%}")
        
        # åˆ†æ•°åˆ†æ
        halluc_scores = [r['score'] for r in results if r['actual']]
        non_halluc_scores = [r['score'] for r in results if not r['actual']]
        
        if halluc_scores:
            avg_halluc_score = sum(halluc_scores) / len(halluc_scores)
            print(f"   æœ‰å¹»è§‰æ ·æœ¬å¹³å‡åˆ†æ•°: {avg_halluc_score:.4f} (n={len(halluc_scores)})")
        
        if non_halluc_scores:
            avg_non_halluc_score = sum(non_halluc_scores) / len(non_halluc_scores)
            print(f"   æ— å¹»è§‰æ ·æœ¬å¹³å‡åˆ†æ•°: {avg_non_halluc_score:.4f} (n={len(non_halluc_scores)})")
    
    else:
        print("   âŒ æ²¡æœ‰æˆåŠŸçš„è¯„ä¼°ç»“æœ")


def analyze_sample_details():
    """åˆ†æå…·ä½“æ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯"""
    print("\n\nğŸ” è¯¦ç»†æ ·æœ¬åˆ†æ")
    print("=" * 50)
    
    loader = RAGtruthLoader()
    
    # è·å–ä¸€ä¸ªæœ‰å¹»è§‰çš„æ ·æœ¬
    samples_with_halluc = loader.get_samples(
        has_hallucination=True,
        max_samples=1,
        random_seed=123
    )
    
    # è·å–ä¸€ä¸ªæ— å¹»è§‰çš„æ ·æœ¬
    samples_without_halluc = loader.get_samples(
        has_hallucination=False,
        max_samples=1,
        random_seed=456
    )
    
    for label, samples in [("æœ‰å¹»è§‰æ ·æœ¬", samples_with_halluc), ("æ— å¹»è§‰æ ·æœ¬", samples_without_halluc)]:
        if samples:
            sample = samples[0]
            print(f"\nğŸ“‹ {label}åˆ†æ:")
            
            # å®‰å…¨åœ°å¤„ç†æºä¿¡æ¯
            source_info = sample.source.source_info
            if isinstance(source_info, dict):
                source_preview = str(source_info)[:200]
            else:
                source_preview = str(source_info)[:200]
            
            generated_preview = str(sample.generated_text)[:200]
            print(f"   æºä¿¡æ¯: {source_preview}...")
            print(f"   ç”Ÿæˆæ–‡æœ¬: {generated_preview}...")
            
            if sample.has_hallucination:
                print(f"   å¹»è§‰è¯¦æƒ…:")
                for j, label_info in enumerate(sample.response.labels, 1):
                    print(f"      {j}. å¹»è§‰æ–‡æœ¬: \"{label_info.text}\"")
                    print(f"         ç±»å‹: {label_info.label_type}")
                    print(f"         ä½ç½®: {label_info.start}-{label_info.end}")
                    print(f"         è¯´æ˜: {label_info.meta[:100]}...")


def comprehensive_test():
    """è¿›è¡Œæ›´å…¨é¢çš„æµ‹è¯•"""
    print("\n" + "ğŸ”¬ å…¨é¢æµ‹è¯•æ¨¡å¼")
    print("=" * 60)
    
    # ä¸åŒè§„æ¨¡çš„æµ‹è¯•
    test_sizes = [10, 25, 50]
    
    for test_size in test_sizes:
        print(f"\nğŸ“Š æµ‹è¯• {test_size} ä¸ªæ ·æœ¬:")
        print("-" * 40)
        
        try:
            loader = RAGtruthLoader()
            evaluator = IntegratedHallucinationEvaluator(
                vectara_api_key="zut_aE6JAgOK4H3CaDxnaz4rEfq8fI9FrYOJr_Es2g"
            )
            
            samples = loader.get_samples(
                split=SplitType.TEST,
                max_samples=test_size,
                random_seed=42
            )
            
            results = []
            successful_evaluations = 0
            
            for i, sample in enumerate(samples, 1):
                if i % 10 == 0 or i == len(samples):
                    print(f"   è¿›åº¦: {i}/{len(samples)} ({i/len(samples)*100:.1f}%)")
                
                # è·³è¿‡æºä¿¡æ¯è¿‡çŸ­çš„æ ·æœ¬
                source_info_str = str(sample.source.source_info)
                if len(source_info_str.strip()) < 10:
                    continue
                
                try:
                    result = evaluator.evaluate(
                        generated_text=sample.generated_text,
                        source_texts=sample.source_texts,
                        method=EvaluationMethod.HHEM_ONLY
                    )
                    
                    if result.success and result.hhem_success:
                        successful_evaluations += 1
                        predicted_hallucination = result.hhem_score < 0.5
                        actual_hallucination = sample.has_hallucination
                        
                        results.append({
                            'actual': actual_hallucination,
                            'predicted': predicted_hallucination,
                            'score': result.hhem_score,
                            'correct': predicted_hallucination == actual_hallucination
                        })
                        
                except Exception as e:
                    continue
            
            # è®¡ç®—ç»Ÿè®¡ç»“æœ
            if results:
                correct_predictions = sum(1 for r in results if r['correct'])
                accuracy = correct_predictions / len(results)
                
                # è®¡ç®—æ··æ·†çŸ©é˜µ
                tp = sum(1 for r in results if r['actual'] and r['predicted'])  # çœŸé˜³æ€§
                fp = sum(1 for r in results if not r['actual'] and r['predicted'])  # å‡é˜³æ€§
                tn = sum(1 for r in results if not r['actual'] and not r['predicted'])  # çœŸé˜´æ€§
                fn = sum(1 for r in results if r['actual'] and not r['predicted'])  # å‡é˜´æ€§
                
                precision = tp / (tp + fp) if (tp + fp) > 0 else 0
                recall = tp / (tp + fn) if (tp + fn) > 0 else 0
                f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
                
                print(f"   âœ… æˆåŠŸè¯„ä¼°: {successful_evaluations}/{len(samples)} æ ·æœ¬")
                print(f"   ğŸ¯ å‡†ç¡®ç‡: {accuracy:.3f} ({correct_predictions}/{len(results)})")
                print(f"   ğŸ“Š ç²¾ç¡®ç‡: {precision:.3f}")
                print(f"   ğŸ“Š å¬å›ç‡: {recall:.3f}")
                print(f"   ğŸ“Š F1åˆ†æ•°: {f1:.3f}")
                
                # åˆ†æ•°åˆ†å¸ƒ
                halluc_scores = [r['score'] for r in results if r['actual']]
                non_halluc_scores = [r['score'] for r in results if not r['actual']]
                
                if halluc_scores and non_halluc_scores:
                    avg_halluc = sum(halluc_scores) / len(halluc_scores)
                    avg_non_halluc = sum(non_halluc_scores) / len(non_halluc_scores)
                    print(f"   ğŸ“ˆ æœ‰å¹»è§‰æ ·æœ¬å¹³å‡åˆ†æ•°: {avg_halluc:.4f} (n={len(halluc_scores)})")
                    print(f"   ğŸ“ˆ æ— å¹»è§‰æ ·æœ¬å¹³å‡åˆ†æ•°: {avg_non_halluc:.4f} (n={len(non_halluc_scores)})")
            else:
                print("   âŒ æ²¡æœ‰æˆåŠŸçš„è¯„ä¼°ç»“æœ")
                
        except Exception as e:
            print(f"   âš ï¸ æµ‹è¯•å¤±è´¥: {e}")


def dataset_overview():
    """æ•°æ®é›†æ¦‚è§ˆ"""
    print("\nğŸ“Š RAGtruth æ•°æ®é›†æ¦‚è§ˆ")
    print("=" * 50)
    
    loader = RAGtruthLoader()
    loader.print_statistics()
    
    # å„ä»»åŠ¡ç±»å‹çš„æ ·æœ¬åˆ†å¸ƒ
    print(f"\nğŸ“‹ æµ‹è¯•é›†æ ·æœ¬åˆ†å¸ƒ:")
    test_samples = loader.get_samples(split=SplitType.TEST, max_samples=None)
    
    task_stats = {}
    halluc_stats = {}
    
    for sample in test_samples:
        task_type = sample.source.task_type
        has_halluc = sample.has_hallucination
        
        # ä»»åŠ¡ç±»å‹ç»Ÿè®¡
        if task_type not in task_stats:
            task_stats[task_type] = {'total': 0, 'with_halluc': 0}
        task_stats[task_type]['total'] += 1
        if has_halluc:
            task_stats[task_type]['with_halluc'] += 1
    
    for task_type, stats in task_stats.items():
        halluc_rate = stats['with_halluc'] / stats['total'] * 100
        print(f"   {task_type}: {stats['total']} æ ·æœ¬ (å¹»è§‰ç‡: {halluc_rate:.1f}%)")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='RAGtruth æ•°æ®é›†æµ‹è¯•')
    parser.add_argument('--samples', type=int, default=5, 
                        help='å¿«é€Ÿæµ‹è¯•çš„æ ·æœ¬æ•°é‡ (é»˜è®¤: 5)')
    parser.add_argument('--comprehensive', action='store_true',
                        help='è¿è¡Œå…¨é¢æµ‹è¯• (10, 25, 50 æ ·æœ¬)')
    parser.add_argument('--overview', action='store_true',
                        help='æ˜¾ç¤ºæ•°æ®é›†æ¦‚è§ˆ')
    parser.add_argument('--qwen', action='store_true',
                        help='ä½¿ç”¨ Qwen è¯„ä¼°å™¨è€Œä¸æ˜¯ HHEM')
    
    args = parser.parse_args()
    
    if args.overview:
        dataset_overview()
    
    if args.comprehensive:
        comprehensive_test()
    else:
        # è¿è¡Œå¿«é€Ÿæµ‹è¯•
        quick_test_on_ragtruth(max_samples=args.samples, use_qwen=args.qwen)
    
    # å§‹ç»ˆè¿è¡Œæ ·æœ¬è¯¦æƒ…åˆ†æ
    analyze_sample_details()
